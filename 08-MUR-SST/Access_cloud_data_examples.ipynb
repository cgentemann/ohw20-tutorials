{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Access cloud data examples tutorial\n",
    "\n",
    "- Funding: Interagency Implementation and Advanced Concepts Team [IMPACT](https://earthdata.nasa.gov/esds/impact) for the Earth Science Data Systems (ESDS) program and AWS Public Dataset Program\n",
    "  \n",
    "### Credits: Tutorial development\n",
    "* [Dr. Chelle Gentemann](mailto:gentemann@faralloninstitute.org) -  [Twitter](https://twitter.com/ChelleGentemann)   - Farallon Institute\n",
    "\n",
    "Credits: Tutorial review and comments.\n",
    "* [Dr. Ed Armstrong](mailto:edward.m.armstrong@jpl.nasa.gov) - JPL PODAAC\n",
    "\n",
    "### Data proximate computing: These are BIG datasets that you can analyze on the cloud without downloading the data. \n",
    "\n",
    "### Here we will demonstrate some ways to access the:\n",
    "- AWS MUR sea surface temperatures\n",
    "- AWS GOES sea surface temperatures\n",
    "- AWS Himawari sea surface temperatures\n",
    "\n",
    "### To run this notebook\n",
    "\n",
    "Code is in the cells that have <span style=\"color: blue;\">In [  ]:</span> to the left of the cell and have a colored background\n",
    "\n",
    "To run the code:\n",
    "- option 1) click anywhere in the cell, then hold shift and press Enter\n",
    "- option 2) click on the Run button at the top of the page in the dashboard\n",
    "\n",
    "### First start by importing libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# filter some warning messages\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "import xarray as xr\n",
    "import fsspec\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import intake\n",
    "import dask\n",
    "import s3fs\n",
    "\n",
    "xr.set_options(display_style=\"html\")  #display dataset nicely \n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 12, 6\n",
    "%config InlineBackend.figure_format = 'retina' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start a cluster, a group of computers that will work together.\n",
    "\n",
    "(A cluster is the key to big data analysis on on Cloud.)\n",
    "\n",
    "- This will set up a [dask kubernetes](https://docs.dask.org/en/latest/setup/kubernetes.html) cluster for your analysis and give you a path that you can paste into the top of the Dask dashboard to visualize parts of your cluster.  \n",
    "- You don't need to paste the link below into the Dask dashboard for this to work, but it will help you visualize progress.\n",
    "- Try 20 workers to start (during the tutorial) but you can increase to speed things up later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "from dask.distributed import Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gateway = Gateway()\n",
    "cluster = gateway.new_cluster()\n",
    "cluster.adapt(minimum=1, maximum=20)\n",
    "client = Client(cluster)\n",
    "cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ☝️ Don’t forget to click the link above or copy it to the Dask dashboard on the left to view the scheduler dashboard! **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [MUR SST](https://podaac.jpl.nasa.gov/Multi-scale_Ultra-high_Resolution_MUR-SST) [AWS Public dataset program](https://registry.opendata.aws/mur/) \n",
    "\n",
    "### Access the MUR SST which is in an s3 bucket.  \n",
    "### This Pangeo binder is running on Google Cloud and data access will be slower than running it on AWS.  \n",
    "\n",
    "![image](https://podaac.jpl.nasa.gov/Podaac/thumbnails/MUR-JPL-L4-GLOB-v4.1.jpg)\n",
    "\n",
    "This code is an example of how to read from a s3 bucket.  \n",
    "\n",
    "Right now (2/16/2020) this takes ~1min on AWS and ~2 min on google cloud, there are two issues here and we are working to solve both.  \n",
    "1. In our Zarr datastore the time coodinate is chunked.  We should have this fixed by 3/1/2020.\n",
    "1. Some shortcomings in the s3fs and zarr formats have been identified.  To work on these, git issues were raised to the developers [here](https://github.com/dask/s3fs/issues/285) and [here](https://github.com/zarr-developers/zarr-python/issues/536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#file_location = 's3://mur-sst/zarr'\n",
    "file_location = 's3://ds-projects/eodc/mursst/6443x100x100-group.zarr'\n",
    "ds_sst = xr.open_zarr(fsspec.get_mapper(file_location, anon=True),consolidated=True)\n",
    "ds_sst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read entire 10 years of data at 1 point.\n",
    "\n",
    "Select the ``analysed_sst`` variable over a specific time period, `lat`, and `lon` and load the data into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_timeseries = ds_sst['analysed_sst'].sel(time=slice('2010-01-01','2020-01-01'),\n",
    "                                            lat=47,\n",
    "                                            lon=-145\n",
    "                                           ).load()\n",
    "sst_timeseries.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The anomaly is more interesting...  \n",
    "\n",
    "Use [.groupby](http://xarray.pydata.org/en/stable/generated/xarray.DataArray.groupby.html#xarray-dataarray-groupby) method to calculate the climatology and [.resample](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.resample.html#xarray-dataset-resample) method to then average it into 1-month bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "sst_climatology = sst_timeseries.groupby('time.dayofyear').mean('time',keep_attrs=True,skipna=False)\n",
    "sst_anomaly = sst_timeseries.groupby('time.dayofyear')-sst_climatology\n",
    "sst_anomaly_monthly = sst_anomaly.resample(time='1MS').mean()\n",
    "\n",
    "#plot the data\n",
    "sst_anomaly.plot()\n",
    "sst_anomaly_monthly.plot()\n",
    "plt.axhline(linewidth=2,color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read AWS GOES SSTs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_goes_fnames(lyr,idyjl):\n",
    "    import s3fs\n",
    "    file_ob=[]\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    file_location = fs.glob('s3://noaa-goes16/ABI-L2-SSTF/'+str(lyr).zfill(4)+'/'+str(idyjl).zfill(3)+'/*/*.nc')\n",
    "    if len(file_location)<1:\n",
    "        return file_ob\n",
    "    for file in file_location:\n",
    "        file_ob.append(fs.open(file))\n",
    "    return file_ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyr=2020\n",
    "idyjl=200\n",
    "file_ob = get_goes_fnames(lyr,idyjl)\n",
    "ds=xr.open_mfdataset(file_ob,combine='nested',concat_dim='time') #note file is super messed up formatting\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ouch! That is a mess!  Let's clean it up\n",
    "- [.reset_coords](http://xarray.pydata.org/en/stable/generated/xarray.Dataset.reset_coords.html#xarray.Dataset.reset_coords) makes all non-index coordinates in this dataset to reset into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.reset_coords()\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds.sel(x=slice(-0.01,0.07215601),y=slice(0.12,0.09))  #reduce to GS region\n",
    "masked = ds.SST.where(ds.DQF==0)\n",
    "tdate = np.datetime64(str(lyr).zfill(4)+'-'+'01-01')+np.timedelta64(idyjl,'D')\n",
    "masked=masked.assign_coords({'time':tdate}).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if istart==0:\n",
    "    dy_total = total_lowres\n",
    "    istart=1\n",
    "else:\n",
    "    dy_total = xr.concat([dy_total,total_lowres],dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read CMIP6 data from Google Cloud using intake\n",
    "\n",
    "<img src=\"https://www.carbonbrief.org/wp-content/uploads/2019/11/cmip6_mips.jpg\" alt=\"drawing\" width=300>\n",
    "\n",
    "The CMIP6 data is a huge collection of different experiements.  Access to these data uses the [intake-esm](https://github.com/NCAR/intake-esm) library which you then use the catalog to select specific variables, experiments, or activities. (**Note: intake-esm is quite news and experimental.**)  There are some great tutorials [here](https://github.com/hdrake/cmip6-temperature-demo/) and [here](https://github.com/pangeo-data/pangeo-cmip6-examples/).\n",
    "\n",
    "More information on CMIP6 is [here](https://www.earthsystemcog.org/projects/wip/CMIP6DataRequest) and variable names [here](https://docs.google.com/document/d/1h0r8RZr_f3-8egBMMh7aqLwy3snpD6_MrDz1q8n5XUk/edit)\n",
    "\n",
    "A nice introduction is [here](https://towardsdatascience.com/a-quick-introduction-to-cmip6-e017127a49d3)\n",
    "\n",
    "The Pangeo catalog listing is [here](https://pangeo-data.github.io/pangeo-datastore/cmip6_pangeo.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "col = intake.open_esm_datastore(\"https://raw.githubusercontent.com/NCAR/intake-esm-datastore/master/catalogs/pangeo-cmip6.json\")\n",
    "\n",
    "col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the collection for historical, monthly, air temperature, for one realization\n",
    "\n",
    "You can use the `variable id` (link given above) to search for different parameters, change the `table id` from atmospheric monthly to ocean monthly, 3hrly data etc.  More information on what you can search for is in this [tutorial](https://intake-esm.readthedocs.io/en/latest/notebooks/tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cmip = col.search(experiment_id=['ssp585','historical'],  # pick the `historical` forcing experiment\n",
    "                 table_id='Amon',             # choose to look at atmospheric variables (A) saved at monthly resolution (mon)\n",
    "                 variable_id='tas',           # choose to look at near-surface air temperature (tas) as our variable\n",
    "                 member_id = 'r1i1p1f1')      # arbitrarily pick one realization for each model (i.e. just one set of initial conditions)\n",
    "cat_cmip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data catalog into a dictionary of xarray datasets\n",
    "\n",
    "`dset_dict` is a dictionary of [xarray.Datasets](https://www.carbonbrief.org/wp-content/uploads/2019/11/cmip6_mips.jpg) where its keys refer to compatible groups.\n",
    "\n",
    "We then set the time period we are interested in and create a new dictionary containing the variable of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supress some annoying warnings\n",
    "import logging\n",
    "urllib3_log = logging.getLogger(\"urllib3\")\n",
    "urllib3_log.setLevel(logging.CRITICAL)\n",
    "\n",
    "dset_dict = cat_cmip.to_dataset_dict(zarr_kwargs={'consolidated': True})\n",
    "\n",
    "time_slice = slice('1850','2015') # specific years that bracket our period of interest\n",
    "\n",
    "ds_dict = {}\n",
    "\n",
    "for name, ds in dset_dict.items():\n",
    "    \n",
    "    # rename spatial dimensions if necessary\n",
    "    if ('longitude' in ds.dims) and ('latitude' in ds.dims):\n",
    "        ds = ds.rename({'longitude':'lon', 'latitude': 'lat'}) \n",
    "\n",
    "    #make sure time index is unique, no repeated years....\n",
    "    _, index = np.unique(ds['time'], return_index=True)\n",
    "    ds = ds.isel(time=index)\n",
    "        \n",
    "    ds = ds.sel(time=time_slice) # subset the data for the time period of interest\n",
    "    \n",
    "    # drop redundant coordinates \n",
    "    for coord in ds.coords:\n",
    "        if coord not in ['lat','lon','time']:\n",
    "            ds = ds.drop(coord)\n",
    "    \n",
    "    # Add near-surface air temperature to dictionary\n",
    "    ds_dict[name] = ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at how air temperatures have changed \n",
    "\n",
    "Look at the data we have, and create means for more recent and historical data to examine how air temperatures have changed.  The last step here is to set a data attribute so that when it is plotted the labels are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_temp_diff(ds_cmip, name):\n",
    "    try:\n",
    "        now = ds_cmip.sel(time=slice('2000-01-01','2015-12-31')).mean('time')\n",
    "        then = ds_cmip.sel(time=slice('1850-01-01','1950-12-31')).mean('time')\n",
    "        return (now-then)['tas']\n",
    "    except ValueError as ve:\n",
    "        # some cmip models have weird calendars that cause the above step to fail\n",
    "        print(name, ve)\n",
    "        pass\n",
    "    \n",
    "all_temp_diffs = dask.compute({name: compute_temp_diff(ds_cmip, name)\n",
    "                         for name, ds_cmip in ds_dict.items()})[0]\n",
    "list(all_temp_diffs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'CMIP.NCAR.CESM2-FV2.historical.Amon.gn'\n",
    "temperature_change = all_temp_diffs[model]\n",
    "temperature_change.attrs['long_name'] = 'Change in air temperature (K)'\n",
    "temperature_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the change in temperature\n",
    "\n",
    "Here we use the excellent [cartopy](https://scitools.org.uk/cartopy/docs/latest/) library to plot our data on a projection and add both coastlines and borders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ortho = ccrs.Orthographic(-90, 20)           # define target coordinate frame\n",
    "geo = ccrs.PlateCarree()                     # define origin coordinate frame\n",
    "\n",
    "plt.figure(figsize=(9,7))                    #set the figure size\n",
    "ax = plt.subplot(1, 1, 1, projection=ortho)  #create the axis for plotting\n",
    "\n",
    "q = temperature_change.plot(ax=ax, \n",
    "                            transform = geo, \n",
    "                            cmap='OrRd', \n",
    "                            vmin=0, \n",
    "                            vmax=3) # plot a colormap in transformed coordinates\n",
    "\n",
    "ax.add_feature(cartopy.feature.COASTLINE)\n",
    "ax.add_feature(cartopy.feature.BORDERS, linestyle='-')\n",
    "ax.set_title(f'Global Warming Air Temp - {model}',fontsize=16, ha='center');\n",
    "\n",
    "#plt.savefig('./../../airtemp_warming_patterns.png',dpi=100,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Close the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.close()\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
